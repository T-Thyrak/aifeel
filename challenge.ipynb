{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\CS-Term 10\\NLP\\Mini Project 2\\aifeel\\.venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import dill as model_file\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "\n",
    "from aifeel.util.preprocess import preprocess_text\n",
    "from aifeel.util.feature_extraction import extract_features, feature_to_vector\n",
    "from aifeel.util import gen_dataframe, read_corpus\n",
    "from aifeel.model.nn import NNClassifier\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\CS-Term 10\\NLP\\Mini Project 2\\aifeel\\.venv\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CS-Term 10\\NLP\\Mini Project 2\\aifeel\\.venv\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.3.0 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the file\n",
    "with open(\"export/model/NNClassifier/nn_model_for_challenge.dill\", \"rb\") as f:\n",
    "    loaded_model = model_file.load(f)\n",
    "\n",
    "with open(\"export/model/SVM/svm_model.dill\", \"rb\") as f:\n",
    "    svm_model = model_file.load(f)\n",
    "\n",
    "with open(\"export/model/TFIDFModelClassifier/multinomial_nb_model.dill\", \"rb\") as f:\n",
    "    multinomial_nb_model = model_file.load(f)\n",
    "\n",
    "\n",
    "# load NNClassification vectorizer\n",
    "with open(\"export/model/NNClassifier/vectorizer.dill\", \"rb\") as f:\n",
    "    cv = model_file.load(f)\n",
    "\n",
    "# load multiNB vectorizer\n",
    "vectorizer_for_multi = model_file.load(\n",
    "    open(\"export/model/TFIDFModelClassifier/vectorizer.dill\", \"rb\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_words, positive_words = set(read_corpus(\"negative-words\")), set(\n",
    "    read_corpus(\"positive-words\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer(review):\n",
    "    result = cv.transform([review])\n",
    "    return result.toarray()[0].tolist()\n",
    "\n",
    "def count_sentiment_words(review, sentiment_words):\n",
    "    words = review.split()\n",
    "    return sum(1 for word in words if word in sentiment_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result_challenge(arr, filename):\n",
    "    arr_string = ''.join(map(str, arr))\n",
    "    # Write the string to the file\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(arr_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convet_to_vector(clean_corpus):\n",
    "    features = map(lambda t: extract_features(t, positive_words, negative_words, vectorizer=vectorizer), clean_corpus)\n",
    "    feature_vectors = list(map(lambda f: feature_to_vector(f, vectorizer=True), features))\n",
    "    return feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = read_corpus(\"challenge_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_review_nn(model, reviews):\n",
    "    test_reviews = [preprocess_text(review) for review in reviews]\n",
    "    test_feature = [extract_features(review, positive_words, negative_words, vectorizer=vectorizer) for review in test_reviews]\n",
    "    test_feature_vector = np.array([feature_to_vector(review, vectorizer=True) for review in test_feature])\n",
    "    y_pred = model.predict(test_feature_vector)\n",
    "    return y_pred\n",
    "\n",
    "result_nn = predict_review_nn(loaded_model, reviews)\n",
    "result_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_nn[0:10]\n",
    "#save_result_challenge(result_nn, \"challenge_result/result_nn.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_review_svm(model, reviews):\n",
    "    # Preprocess and extract features (assuming preprocess_text and extract_features return strings)\n",
    "    test_review_preprocess = [preprocess_text(review) for review in reviews]\n",
    "    test_review_feature = [extract_features(review, positive_words, negative_words) for review in test_review_preprocess]\n",
    "    test_review_df = pd.DataFrame(test_review_feature)\n",
    "    #print(test_review_df.head(10))\n",
    "    y_pred = model.predict(test_review_df)\n",
    "    #print(y_pred[0:10])\n",
    "    return y_pred\n",
    "\n",
    "# review_numpy = np.array(reviews)\n",
    "results_svm = predict_review_svm(svm_model, reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5868,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_svm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '1', ..., '1', '1', '0'], dtype='<U1')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_review(model, reviews):\n",
    "    X_tfidf = vectorizer_for_multi.transform(reviews)\n",
    "\n",
    "    positive_word_count = [\n",
    "        count_sentiment_words(review, positive_words) for review in reviews\n",
    "    ]\n",
    "    negative_word_count = [\n",
    "        count_sentiment_words(review, negative_words) for review in reviews\n",
    "    ]\n",
    "\n",
    "    # Combine the tf-idf features with the sentiment word count features\n",
    "    X = hstack([X_tfidf, np.array([positive_word_count, negative_word_count]).T])\n",
    "\n",
    "    y_pred = model.predict(X)\n",
    "    y_prob = model.predict_proba(X)\n",
    "\n",
    "    return y_pred, y_prob\n",
    "\n",
    "result_multiNB = predict_review(multinomial_nb_model, reviews)\n",
    "result_multiNB[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save result to file\n",
    "save_result_challenge(result_nn, \"challenge_result/result_nn.txt\")\n",
    "save_result_challenge(result_multiNB[0], \"challenge_result/result_multiNb.txt\")\n",
    "save_result_challenge(results_svm, \"challenge_result/result_svm.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #808000; text-decoration-color: #808000\">...</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;36m1\u001b[0m \u001b[33m...\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #808000; text-decoration-color: #808000\">...</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;36m1\u001b[0m \u001b[33m...\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">              precision    recall  f1-score   support\n",
       "\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.96</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.87</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.91</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2996</span>\n",
       "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.87</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.96</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.91</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2872</span>\n",
       "\n",
       "    accuracy                           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.91</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5868</span>\n",
       "   macro avg       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.91</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.91</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.91</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5868</span>\n",
       "weighted avg       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.92</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.91</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.91</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5868</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "              precision    recall  f1-score   support\n",
       "\n",
       "           \u001b[1;36m0\u001b[0m       \u001b[1;36m0.96\u001b[0m      \u001b[1;36m0.87\u001b[0m      \u001b[1;36m0.91\u001b[0m      \u001b[1;36m2996\u001b[0m\n",
       "           \u001b[1;36m1\u001b[0m       \u001b[1;36m0.87\u001b[0m      \u001b[1;36m0.96\u001b[0m      \u001b[1;36m0.91\u001b[0m      \u001b[1;36m2872\u001b[0m\n",
       "\n",
       "    accuracy                           \u001b[1;36m0.91\u001b[0m      \u001b[1;36m5868\u001b[0m\n",
       "   macro avg       \u001b[1;36m0.91\u001b[0m      \u001b[1;36m0.91\u001b[0m      \u001b[1;36m0.91\u001b[0m      \u001b[1;36m5868\u001b[0m\n",
       "weighted avg       \u001b[1;36m0.92\u001b[0m      \u001b[1;36m0.91\u001b[0m      \u001b[1;36m0.91\u001b[0m      \u001b[1;36m5868\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(result_nn)\n",
    "print(result_multiNB[0].astype(int))\n",
    "report = classification_report(result_nn, result_multiNB[0].astype(int))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5868</span>,<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m5868\u001b[0m,\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(result_multiNB[0].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
