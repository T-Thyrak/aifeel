{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from rich import print\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from aifeel.model.nn import NNClassifier\n",
    "from aifeel.util import gen_dataframe, read_corpus\n",
    "from aifeel.util.feature_extraction import extract_features, feature_to_vector\n",
    "from aifeel.util.preprocess import preprocess_text\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.01)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.01)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.01)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_corpus, positive_corpus = read_corpus(\"negative-reviews\"), read_corpus(\n",
    "    \"positive-reviews\"\n",
    ")\n",
    "negative_words, positive_words = set(read_corpus(\"negative-words\")), set(\n",
    "    read_corpus(\"positive-words\")\n",
    ")\n",
    "\n",
    "df = gen_dataframe(positive_corpus, negative_corpus, random_state=42)\n",
    "df[\"clean_review\"] = df[\"review\"].apply(preprocess_text)\n",
    "\n",
    "# Create a TfidfVectorizer object\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the cleaned reviews\n",
    "X = vectorizer.fit_transform(df['clean_review'])\n",
    "y = df['tag']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
    "\n",
    "model = LogisticRegression(C=0.01)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tf-idf.joblib']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model\n",
    "from joblib import dump\n",
    "\n",
    "# Assuming svm_model is your trained SVM model\n",
    "# Replace 'svm_model.joblib' with the desired file name/path\n",
    "dump(model, 'lr.joblib')\n",
    "dump(vectorizer, 'tf-idf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = load('lr.joblib')\n",
    "vectorize = load('tf-idf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'0'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'0'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'0'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'0'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'0'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'0'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'0'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'0'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'0'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'0'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'0'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'0'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'0'</span> <span style=\"color: #008000; text-decoration-color: #008000\">'0'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[32m'0'\u001b[0m \u001b[32m'0'\u001b[0m \u001b[32m'0'\u001b[0m \u001b[32m'0'\u001b[0m \u001b[32m'0'\u001b[0m \u001b[32m'0'\u001b[0m \u001b[32m'0'\u001b[0m \u001b[32m'0'\u001b[0m \u001b[32m'0'\u001b[0m \u001b[32m'0'\u001b[0m \u001b[32m'0'\u001b[0m \u001b[32m'0'\u001b[0m \u001b[32m'0'\u001b[0m \u001b[32m'0'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['absolutely wonderful silky sexy comfortable',\n",
       " 'love dress ! sooo pretty i happened find store i glad i bc i never would ordered online bc petite i bought petite 5 8 i love length me hit little knee would definitely true midi someone truly petite',\n",
       " 'i high hope dress really wanted work me i initially ordered petite small my usual size i found outrageously small small fact i could NOT_zip NOT_it NOT_up ! i reordered petite medium ok overall top half comfortable fit nicely bottom half tight layer several somewhat cheap net layer imo major design flaw net layer sewn directly zipper c',\n",
       " 'i love love love jumpsuit fun flirty fabulous ! every time i wear i get nothing great compliment !',\n",
       " 'shirt flattering due adjustable front tie perfect length wear legging sleeveless pair well cardigan love shirt ! ! !',\n",
       " 'i love tracy reese dress one NOT_for NOT_the NOT_very NOT_petite NOT_i NOT_am NOT_just NOT_under NOT_5 NOT_feet NOT_tall NOT_and NOT_usually NOT_wear NOT_a NOT_0p NOT_in NOT_this NOT_brand NOT_this NOT_dress NOT_was NOT_very NOT_pretty NOT_out NOT_of NOT_the NOT_package NOT_but NOT_its NOT_a NOT_lot NOT_of NOT_dress NOT_the NOT_skirt NOT_is NOT_long NOT_and NOT_very NOT_full NOT_so NOT_it NOT_overwhelmed NOT_my NOT_small NOT_frame NOT_a NOT_stranger NOT_to NOT_alterations NOT_shortening NOT_and NOT_narrowing NOT_the NOT_skirt NOT_would NOT_take NOT_away NOT_from NOT_the NOT_embellishment NOT_of NOT_the NOT_garment NOT_i NOT_love NOT_the NOT_color NOT_and NOT_the NOT_idea NOT_of NOT_the NOT_style NOT_but NOT_it NOT_just NOT_did work me i returned dress',\n",
       " 'i aded my basket hte last mintue see would look like person store pick i went teh darkler color i pale hte color really gorgeous turn mathced everythiing i trying prefectly little baggy me hte x hte msallet size bummer petite i decided jkeep though i said matvehd everything my ejans pant 3 skirt i waas trying i kept oops',\n",
       " 'i ordered carbon store pick ton stuff always try used top pair skirt pant everything went color really nice charcoal shimmer went well pencil skirt flare pant etc my compaint bit big sleeve long go petite also bit loose me xx i kept wil ldecide later since light color already sold hte smallest size',\n",
       " 'i love dress i usually get x run little snug bust i ordered size flattering feminine usual retailer flair style',\n",
       " 'i 5 5 125 lb i ordered petite make sure length long i typically wear x regular retailer dress you le busty 34b cup smaller petite fit you perfectly snug tight i love i could dress party work i love tulle longer fabric underneath',\n",
       " 'dress run small esp zipper area run i ordered sp typically fit me tight ! material top look feel cheap even pulling cause rip fabric pretty disappointed going my christmas dress year ! needle say going back',\n",
       " 'dress perfection ! pretty flattering',\n",
       " 'i find reliant review written savvy shopper me past right estimation product case dress NOT_been NOT_for NOT_the NOT_reveiws NOT_i NOT_doubt NOT_i NOT_would NOT_have NOT_even NOT_tried NOT_this NOT_the NOT_dress NOT_is NOT_beautifully NOT_made NOT_lined NOT_and NOT_reminiscent NOT_of NOT_the NOT_old NOT_retailer NOT_quality NOT_it NOT_is NOT_lined NOT_in NOT_the NOT_solid NOT_periwinkle NOT_colored NOT_fabric NOT_that NOT_matches NOT_the NOT_outer NOT_fabric NOT_print NOT_tts NOT_and NOT_very NOT_form NOT_fitting NOT_falls NOT_just NOT_above NOT_the NOT_knee NOT_and NOT_does rid',\n",
       " 'i like movie']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def classify_reviews(file_name, output_file_name = 'result_testing_challenge.txt'):\n",
    "    # read challenge file\n",
    "    reviews = read_corpus(file_name)\n",
    "    # preprocess text\n",
    "    clean_reviews = [preprocess_text(review) for review in reviews]\n",
    "    # initailize feature extraction technique\n",
    "    X = vectorize.transform(clean_reviews)\n",
    "\n",
    "    predictions = loaded_model.predict(X)\n",
    "    print(predictions)\n",
    "\n",
    "    with open(output_file_name, 'w') as output_file:\n",
    "        for prediction in predictions:\n",
    "            output_file.write(f\"{prediction}\\n\")\n",
    "\n",
    "\n",
    "    return clean_reviews\n",
    "classify_reviews('testing-challeng')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
